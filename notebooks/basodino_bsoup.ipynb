{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDf-lEPcB3Ij"
      },
      "outputs": [],
      "source": [
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQ0UhzapQINi"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import string\n",
        "import array as arr\n",
        "import re\n",
        "import itertools\n",
        "from itertools import product\n",
        "from itertools import combinations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7E7RndRQJ87",
        "outputId": "9060439b-744b-464b-e771-411b71325885"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Abae', 'Abale', 'Aballaba', 'Aballava', 'abamita', 'Abantiades', 'abavia', 'abbatia', 'abbatissa', 'Abbia', 'abbreviatura', 'Abdara', 'Abdera', 'Abderites', 'Abdua', 'abecedaria', 'Abella', 'abellana', 'Abeona', 'Abia', 'Abias', 'abiga', 'Abila', 'ablepsia', 'abmatertera', 'Aboa', 'Abobriga', 'abolla', 'abra', 'Abraham', 'abscissa', 'absconsa', 'absentia', 'absinthites', 'abstantia', 'abstinentia', 'absynthites', 'Absyra', 'Abula', 'Abulfeda', 'abulia', 'abundantia', 'Abusina', 'Abutuca', 'Abyla', 'Abzoae', 'acacia', 'academia', 'Acadia', 'acalephe', 'Acarnania', 'acatalepsia', 'Accaronita', 'Accaronites', 'acceia', 'accepta', 'accidentia', 'accidia', 'accipitrina', 'accola', 'Accua', 'acedia', 'acernia', 'acerra', 'Acerrae', 'acersecomes', 'Acesines', 'Acestes', 'acetosella', 'Achaia', 'Acharnae', 'acharne', 'achates', 'Achates', 'acheta', 'Achillas', 'Acholla', 'achromia', 'acia', 'acicula', 'Acidalia', 'acina', 'Acmonia', 'acne', 'acnua', 'Acoetes', 'acona', 'acqua', 'Acrae', 'Acraephia', 'acredula', 'Acrillae', 'acrimonia', 'Acrisioniades', 'Acritas', 'acta', 'actaea', 'acte', 'Acte', 'actuariola', 'acucula', 'acula', 'acupunctura', 'acutia', 'Adada', 'adarca', 'adarce', 'adasia', 'adcola', 'Addua', 'Adeona', 'adfluentia', 'adhaerentia', 'Adhelina', 'Adiabene', 'administra', 'administratiuncula', 'admonitiuncula', 'Adolenda', 'adorea', 'adoria', 'adpetentia', 'Adrabigania', 'Adrana', 'Adriana', 'adrogantia', 'adsecula', 'adstutia', 'Adua', 'Aduatuca', 'adulescentia', 'adulescentula', 'adultera', 'Aduna', 'advena', 'adversa', 'adversaria', 'advertentia', 'Adyrmachidae', 'Aeacides', 'Aeaea', 'Aebura', 'Aecae', 'Aedesa', 'aedicula', 'aeditua', 'Aeetes', 'Aefula', 'Aegae', 'Aegiae', 'Aegida', 'Aegides', 'Aegina', 'Aeginetes', 'Aegira', 'aegrimonia', 'Aegusa', 'aegyptilla', 'Aemilia', 'Aenaria', 'Aeneas', 'Aeningia', 'Aenona', 'Aeoliae', 'Aequatoria', 'aequivalentia', 'aera', 'aerizusa', 'aeromantia', 'aeruca', 'aerumna', 'Aesernia', 'aetatula', 'Aethalia', 'Aethalides', 'Aethiopia', 'aethra', 'Aetna', 'Aetne', 'Aetolia', 'afa', 'afannae', 'Affilae', 'affluentia', 'Afgania', 'Africa', 'africia', 'Aga', 'agaga', 'Agamatae', 'agape', 'Agasias', 'Agassae', 'Agatha', 'Agathyrna', 'agea']\n"
          ]
        }
      ],
      "source": [
        "###Script for scraping & cleaning vocabulary from Wiktionary\n",
        "\n",
        "#basic URL format: insert declension number between strings & add page specifier at end of 2nd string#\n",
        "urlstart = \"https://en.wiktionary.org/w/index.php?title=Category:Latin_\"\n",
        "urlend = \"_declension_nouns&from=\"\n",
        "\n",
        "#list of declensions\n",
        "decs = [\"first\",\"second\",\"third\",\"fourth\",\"fifth\"]\n",
        "\n",
        "#empty list to store all letters in alphabet\n",
        "alpha1 = []\n",
        "\n",
        "#function to iterate through all letters and append to list alpha1\n",
        "def show_letters():\n",
        "  for letter in string.ascii_uppercase:\n",
        "    alpha1.append(letter)\n",
        "  return(alpha1)\n",
        "\n",
        "#2nd list same as alpha1 to use in itertool function below\n",
        "alpha2 = show_letters()\n",
        "\n",
        "#Creates array of all possible letter pairs for page addresses in Wiktionary\n",
        "combs = itertools.product(alpha1, repeat=2)\n",
        "combs = [''.join(c) for c in combs]\n",
        "\n",
        "#list for all declension URLs\n",
        "URLS = []\n",
        "#appends declension URLs to list above & adds letter combinations for combs list to end\n",
        "for d in decs:\n",
        "  for c in combs:\n",
        "    u = urlstart+d+urlend+c\n",
        "    list = URLS.append(u)\n",
        "\n",
        "#Pulls HTML for each (takes a long time to run) URL created according to index in 'URLS' list\n",
        "#!for u in URLS:\n",
        " # response = requests.get(u)\n",
        "  #html_content = response.content\n",
        "  #soup = str(BeautifulSoup(html_content,\"html.parser\"))\n",
        "\n",
        "#BeautifulSoup pull for just one page, for testing; pulls HTML for given page of declensions\n",
        "def pull_soup():\n",
        "  sample_response = requests.get(URLS[0])\n",
        "  sample_html_content = sample_response.content\n",
        "  sample_soup = str(BeautifulSoup(sample_html_content,\"html.parser\"))\n",
        "  return(sample_soup)\n",
        "\n",
        "sample_soup = pull_soup()\n",
        "\n",
        "#RegEx pattern for pulling vocabulary between HTML tags\n",
        "tag_pat = re.compile(r\">[\\w]+</a></li>\")\n",
        "#pulls vocabulary from HTML using above pattern\n",
        "parse = re.findall(tag_pat,sample_soup) #! change 'soup' between sample & final version\n",
        "parseclip = parse[20:-3] #excludes the first 20 instances, since those are the two top-10 lists of recent changes on each page\n",
        "\n",
        "#clips leading and trailing HTML tags from vocabulary items in each page of X declension nouns\n",
        "cleanlist = []\n",
        "for item in parseclip:\n",
        "  cleanlist.append(item[1:-9])\n",
        "\n",
        "print(cleanlist)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIk8spgM35WF",
        "outputId": "fc026b63-e1c5-471c-a3c1-0e152f161144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/ˈa.bae̯/', '/ˈa.ba.leː/', '/aˈbal.la.ba/', '/aˈbal.la.u̯a/', '/aˈba.mi.ta/', '', '/aˈba.u̯i.a/', '/abˈbaː.ti.a/', '/ab.baːˈtis.sa/', '/ˈab.bi.a/', '/ab.bre.vi.aˈtu.ra/', '/ˈab.da.ra/', '/abˈdeː.ra/', '/ab.deːˈriː.teːs/', '/ˈab.du.a/', '/a.be.t͡ʃeˈda.ri.a/', '/aˈbel.la/', '/a.belˈlaː.na/', '/a.beˈoː.na/', '/aːˈbiː.a/', '/aˈbi.as/', '/ˈa.bi.ɡa/', '/ˈa.bi.la/', '/aˈblep.si.a/', '/ab.maːˈter.te.ra/', '/ˈa.bo.a/', '/a.boˈbriː.ɡa/', '/aˈbol.la/', '/ˈa.bra/', '/ˈaː.bra.haːm/', '', '/abˈskon.sa/', '/abˈsen.ti.a/', '/ab.sinˈtʰiː.teːs/', '/abˈstan.ti.aː/', '/ab.stiˈnen.ti.a/', '/ab.synˈtʰiː.teːs/', '/ˈab.sy.ra/', '', '', '', '/a.bunˈdan.ti.a/', '/aˈbu.si.na/', '/aˈbu.tu.ka/', '/ˈa.by.la/', '/ˈab.zo.ae̯/', '/aˈkaː.ki.a/', '/a.ka.deːˈmiː.a/</span>, <span class=\"IPA\">[äkäd̪eːˈmiːä]</span> or <a href=\"/wiki/Wiktionary:International_Phonetic_Alphabet\" title=\"Wiktionary:International Phonetic Alphabet\">IPA</a><sup>(<a href=\"/wiki/Appendix:Latin_pronunciation\" title=\"Appendix:Latin pronunciation\">key</a>)</sup>: <span class=\"IPA\">/a.kaˈdeː.mi.a/', '/aˈka.di.a/', '/a.kaˈleː.pʰeː/', '/a.karˈnaː.ni.a/', '/a.ka.taˈlep.si.a/', '/ak.ka.roˈni.ta/', '', '/akˈkei̯.i̯a/', '/akˈkep.ta/', '/ak.kiˈden.ti.a/', '/akˈkiː.di.a/', '/ak.ki.piˈtriː.na/', '/ˈak.ko.la/', '/ˈak.ku.a/', '/aˈkeː.di.a/', '/aˈker.ni.a/', '/aˈker.ra/', '/aˈker.rae̯/', '', '/a.keˈsiː.neːs/', '/aˈkes.teːs/', '', '/aˈkʰaː.i.a/', '/aˈkʰar.nae̯/', '/aˈkʰar.neː/', '/aˈkʰaː.teːs/', '/ˈa.kʰa.teːs/', '', '/aˈkʰil.laːs/', '', '', '', '/aˈki.ku.la/', '/a.kiːˈda.li.a/', '/ˈa.ki.na/', '/akˈmoː.ni.a/', '/ˈak.neː/', '/ˈak.nu.a/', '/aˈkoe̯.teːs/', '/ˈa.ko.na/', '', '/ˈa.krae̯/', '/aˈkrae̯.pʰi.a/', '', '/aˈkril.lae̯/', '/aː.kriˈmoː.ni.a/', '/a.kri.si.oːˈni.a.deːs/', '/aːˈkriː.taːs/', '/ˈaːk.ta/', '', '/ˈak.teː/', '/ˈak.teː/', '', '', '/ˈa.ku.la/', '/a.kuː.puːnkˈtuː.ra/', '/aˈkuː.ti.a/', '/ˈa.da.da/', '/aˈdar.ka/', '/aˈdar.keː/', '', '', '/ˈad.du.a/', '/a.deˈoː.na/', '', '/ad.hae̯ˈren.ti.a/', '/adˈhe.li.na/', '/a.di.aˈbeː.neː/', '/ad.miˈnis.tra/', '', '', '/a.doˈlen.da/', '/aˈdoː.re.a/', '', '/ad.peˈten.ti.a/', '', '/ˈad.ra.na/', '/ad.riˈaː.na/', '', '', '', '/ˈa.du.a/', '/a.duˈaː.tu.ka/', '/a.du.leːsˈken.ti.a/', '/a.du.lesˈken.tu.la/', '/aˈdul.te.ra/', '/ˈa.du.na/', '/ˈad.u̯e.na/', '/adˈu̯er.sa/', '/ad.u̯erˈsaː.ri.a/', '', '', '', '/ae̯ˈae̯.a/', '/ˈae̯.bu.ra/', '/ˈae̯.kae̯/', '/ˈae̯.de.sa/', '/ae̯ˈdi.ku.la/', '', '/ae̯ˈeː.teːs/', '/ˈae̯.fu.la/', '/ˈae̯.ɡae̯/', '/ˈae̯.ɡi.ae̯/', '/ˈae̯.ɡi.da/', '/ae̯ˈɡiː.deːs/', '/ae̯ˈɡiː.na/', '/ae̯.ɡiːˈneː.teːs/', '/ae̯ˈɡiː.ra/', '/ae̯.ɡriˈmoː.ni.a/', '/ae̯ˈɡuː.sa/', '', '/ae̯ˈmi.li.a/', '/ae̯ˈnaː.ri.a/', '/ae̯ˈneː.aːs/', '/ae̯ˈnin.ɡi.a/', '/ˈae̯.no.na/', '/ae̯ˈo.li.ae̯/', '/ae̯.kʷaːˈtoː.ri.a/', '/ae̯.kʷi.u̯aˈlen.ti.a/', '/ˈae̯.ra/', '/aː.e.rizˈzuː.sa/', '/aː.e.ro.manˈtiː.a/', '', '', '/ae̯ˈser.ni.a/', '', '/ae̯ˈtʰa.li.a/', '/ae̯ˈtʰa.li.deːs/', '/ae̯.tʰiˈo.pi.a/', '/ˈae̯.tʰra/', '/ˈae̯t.na/', '/ˈae̯t.neː/', '/ae̯ˈtoː.li.a/', '/ˈa.fa/', '/aˈfan.nae̯/', '/ˈaf.fi.lae̯/', '', '/afˈɡaː.ni.a/', '/ˈaː.fri.ka/', '/aˈfri.ki.a/', '/ˈa.ɡa/', '/ˈa.ɡa.ɡa/', '/aˈɡa.ma.tae̯/', '/ˈa.ɡa.peː/', '/aˈɡa.si.aːs/', '/aˈɡas.sae̯/', '/ˈa.ɡa.tʰa/', '/a.ɡaˈtʰyr.na/', '/aˈɡeː.a/']\n"
          ]
        }
      ],
      "source": [
        "###Returns IPA pronunciation for each vocab item in the list returned by the above block of code in 'cleanlist'\n",
        "\n",
        "#base URL\n",
        "tURL_start = \"https://en.wiktionary.org/wiki/\"\n",
        "tURL_end = \"#Latin\"\n",
        "\n",
        "#empty list for URLs to go into\n",
        "tURLs =[]\n",
        "\n",
        "#puts 'cleanlist' vocab items between start & end URL variables to create URL for that vocab item's page\n",
        "for item in cleanlist:\n",
        "  tURLs.append(tURL_start+item+tURL_end)\n",
        "\n",
        "#take each URL in 'tURLS' list and scrape with BeautifulSoup for its HMTL\n",
        "\n",
        "#returns HTML for a given URL within tURLs\n",
        "def tURL_item():\n",
        "  sample_response2 = requests.get(tURLs[0])                             #<-------pulls given list item from 'tURLs' list based on index ('tURLs[x]')\n",
        "  sample_html_content2 = sample_response2.content\n",
        "  sample_soup2 = str(BeautifulSoup(sample_html_content2,\"html.parser\"))\n",
        "  return(sample_soup2)\n",
        "\n",
        "#Returns HTML for all URLs within tURLs as list of HTML blocks\n",
        "def yank_soup():\n",
        "  tURLs_items = []\n",
        "  for u in tURLs:\n",
        "    response2 = requests.get(u)\n",
        "    html_content2 = response2.content\n",
        "    soup2 = str(BeautifulSoup(html_content2,\"html.parser\"))\n",
        "    yank = tURLs_items.append(soup2)\n",
        "  return(tURLs_items)\n",
        "\n",
        "\n",
        "#returns scraped HTML from above def tURL_item()\n",
        "sample_soup2 =tURL_item()\n",
        "\n",
        "#returns scraped HMTL from above def yank_soup()\n",
        "soup2 = yank_soup()\n",
        "\n",
        "#RegEx to pinpoint IPA pronunciation in HTML ;\n",
        "tag_pat2 = re.compile(r'Appendix\\:Latin pronunciation(.*)</span>') #line 489 in page source code   ; <span class=\\\"IPA\\\">/.*/</span> ; Appendix\\:Latin pronunciation\\\">key</a>\\)</sup>:\\&\\#32;<span class=\\\"IPA\\\">/.*/</span>\n",
        "tag_pat3 = re.compile(r'IPA\\\">/.*/</span>')\n",
        "#pulls 1st IPA pronunciation listed in HTML for given vocab item (i.e.:'[0]')\n",
        "#parse2 = re.findall(tag_pat2,tURLs_items)                                      #<-----! change 'soup' between sample & final version; do not change the '[0]' index!\n",
        "def parser():\n",
        "  IPA = []\n",
        "  for html in soup2:\n",
        "    parsed = re.findall(tag_pat2,html)\n",
        "    if parsed:\n",
        "      IPA.append(parsed[0])\n",
        "    else:\n",
        "      IPA.append('')\n",
        "  return(IPA)\n",
        "\n",
        "def parser2():     #to run the result of def parser() through the 'tag_pat3' RegEx\n",
        "  IPA2 = []\n",
        "  for html in parser():\n",
        "    parsed = re.findall(tag_pat3,html)\n",
        "    if parsed:\n",
        "      IPA2.append(parsed[0])\n",
        "    else:\n",
        "      IPA2.append('')\n",
        "  return(IPA2)\n",
        "\n",
        "\n",
        "parse2 = parser()\n",
        "parse3 = parser2()\n",
        "\n",
        "#clips leading and trailing HTML tags from IPA pronunciations\n",
        "def clean2():\n",
        "  clean2 = []\n",
        "  for item in parse3:\n",
        "    clean2.append(item[5:-7])\n",
        "  return(clean2)\n",
        "\n",
        "clean2 = clean2()\n",
        "\n",
        "print(clean2)  #print 'parse2' variable to return whole block\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QBhy4052yhJ",
        "outputId": "41f0298f-506d-4849-b5a3-5670d3aac288"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ab', 'abal', 'aballabe', 'aballabe', 'abamte', '', 'abaibje', 'appaisce', 'appacesse', 'aippje', 'abbreviaçûre', 'abdare', 'abdîre', 'abdereisz', 'abdue', 'abecedairje', 'abelle', 'abellane', 'aibjûne', 'abeie', 'aibjas', 'abɡe', 'able', 'ablepsje', 'abmacertre', 'aboe', 'abobreiɡe', 'abolle', 'abre', 'abram', '', 'abscose', 'absencje', 'absenceisz', 'abstaincje', 'abstenencje', 'absynceisz', 'absre', '', '', '', 'abondaincje', 'abûsne', 'abûtque', 'able', 'abzo', 'achaice', 'achademeia<span>, <span class=\"IPA\">[äcäd̪emiä]<span> or <a ref=\"weciWectionary:Incernascional_Ponescic_Alphabet\" tetle=\"Wectionary:Incernascional Ponescic Alphabet\">IPA<a><sop>(<a ref=\"weciAppendix:Lascen_prononciascion\" tetle=\"Appendix:Lascen prononciascion\">cey<a>)<sop>: <span class=\"IPA\">achadîmje', 'achaije', 'achalîff', 'acharnainje', 'achasçalepsje', 'acharonîsce', '', 'aiccejje', 'accet\\\\te', 'accedencje', 'acceije', 'acciffetreine', 'achole', 'acque', 'acîje', 'acernje', 'acerre', 'acerr', '', 'acesein', 'acest', '', 'achaie', 'acharn', 'acharn', 'achasz', 'achasz', '', 'acellas', '', '', '', 'acîcle', 'aicidailje', 'acne', 'acmûinje', 'acn', 'acnue', 'acîsz', 'achone', '', 'acr', 'acreffie', '', 'acrell', 'acremûinje', 'acrisjoinjad', 'acreisças', 'at\\\\te', '', 'at\\\\t', 'at\\\\t', '', '', 'acle', 'achuffuncçoure', 'achouisce', 'adade', 'adarche', 'adarz', '', '', 'adde', 'aidjûne', '', 'aderencje', 'adelne', 'aidjabîn', 'admenestre', '', '', 'adolende', 'adûirje', '', 'adpecencje', '', 'adrane', 'aidrjane', '', '', '', 'adue', 'aduatque', 'adulescencje', 'adulescentle', 'adoltre', 'adne', 'adu̯ene', 'adverse', 'adu̯ersairje', '', '', '', 'eee', 'ebure', 'ez', 'edese', 'edîcle', '', 'eîsz', 'efule', 'eɡ', 'eɡ', 'eɡide', 'eɡeid', 'eɡeine', 'eɡinîsz', 'eɡeire', 'eɡremûinje', 'eɡouse', '', 'emîlje', 'enairje', 'enîas', 'enenje', 'enone', 'eol', 'ecʷaçûirje', 'ecʷibalencje', 'ere', 'aerizzouse', 'aeromanceie', '', '', 'esernje', '', 'eçailje', 'eçald', 'escioipje', 'etre', 'etne', 'etn', 'eçûilje', 'afe', 'afann', 'affil', '', 'afɡainje', 'afriche', 'afrîce', 'aɡe', 'aɡaɡe', 'aɡamasz', 'aɡaff', 'aɡaisjas', 'aɡass', 'aɡasce', 'aɡacyrne', 'aɡîe']\n"
          ]
        }
      ],
      "source": [
        "#Basodino sound change script\n",
        "\n",
        "#for applying changes to user input\n",
        "#word = input()\n",
        "\n",
        "#for pulling word from previous block of code\n",
        "word = clean2\n",
        "\n",
        "def basodino(word):\n",
        "    def vulg_lat(text):\n",
        "        #shifts short vowels\n",
        "        text = re.sub(r'u(\\ˈ*)([bptdkɡslnmrf])',r'o\\1\\2',text)\n",
        "        text = re.sub(r'i(\\ˈ*)([bptdkɡslnmrf])',r'e\\1\\2',text)\n",
        "        #reduces short vowels in hiatus\n",
        "        pattern_dim = r'(ˈ\\w+\\.)(b|p|t|d|g|ɡ|k|c|s|r|l|n|m)(u|i|y|e)\\.(b|p|t|d|g|ɡ|k|c|s|r|l|n|m)'\n",
        "        text = re.sub(pattern_dim,r'\\1\\2\\4',text)\n",
        "        #removes nasals before fricatives;\n",
        "        pattern_spir = r'(n\\.*|m\\.*)(s|f)'\n",
        "        pattern_ae = r'ae̯'\n",
        "        pattern_oe = r'oe̯'\n",
        "        pattern_back_w = r'(a|e|i|o|u)(\\ː*)(\\.*)(u̯)(o|u)'\n",
        "        pattern_w = r'(a|e|i|o|u)(\\ː*)(\\.*)(u̯)(a|e|i)'\n",
        "        hiatus_w = r'(ˈ\\w+\\.)(b|p|t|d|ɡ|g|k|c|s|r|l|n|m)(u|ʷ)(\\.*u|\\.*o)' #2 g's b/c IPA 'g' is technically different I guess?\n",
        "        hiatus_w_2 = r'(\\ˈ*)u\\.*(\\ˈ*o)'\n",
        "        hiatus_j = r'(ˈ\\w+\\.)(b|p|t|d|ɡ|g|k|c|s|r|l|n|m|ʷ)(i|i̯|e)(\\.)(a|e|i|o|u)'\n",
        "        hiatus_j_2 = r'(b|p|t|d|ɡ|g|k|c|s|r|l|n|m|ʷ)(i|i̯|e)(\\.|\\ˈ)(a|e|i|o|u)'\n",
        "        gem_w = r'(ˈ\\w+)(b\\.b|p\\.p|t\\.t|d\\.d|ɡ\\.ɡ|g\\.g|k\\.k|c|s\\.s|r\\.r|l\\.l|n\\.n|m\\.m)u(\\.\\w+)'\n",
        "\n",
        "        #removes h between like vowels\n",
        "        text = re.sub(r'a\\ː*\\.*\\ˈ*ha\\ː*','a', text)\n",
        "        text = re.sub(r'o\\ː*\\.*\\ˈ*ho\\ː*','oː', text)\n",
        "        text = re.sub(r'u\\ː*\\.*\\ˈ*hu\\ː*','uː', text)\n",
        "        text = re.sub(r'e\\ː*\\.*\\ˈ*he\\ː*','eː', text)\n",
        "        text = re.sub(r'i\\ː*\\.*\\ˈ*hi\\ː*','iː', text)\n",
        "        #simplifies /kt/ & /pt/ to /tt/\n",
        "        text = re.sub(r'[kp]\\.t',r't\\.t',text)\n",
        "        #removes h from Latin words\n",
        "        text =  re.sub('h', '', text)\n",
        "        #removes nasals before spirants\n",
        "        text = re.sub(pattern_spir,r'ː\\2',text)\n",
        "        text = re.sub(r'(n\\ˈ*|m\\ˈ*)(s|f)',r'ː\\2',text)\n",
        "        #monophthongizes 'ae' to 'e'\n",
        "        text = re.sub(pattern_ae, r'e', text)\n",
        "        #monopthongizes 'oe' to long 'e'\n",
        "        text = re.sub(pattern_oe, r'eː', text)\n",
        "        #deletes /w/ before back rounded vowels\n",
        "        text = re.sub(pattern_back_w, r'\\1\\2\\3\\5',text)\n",
        "        #turns intervocalic 'v','b' into b\n",
        "        text = re.sub(pattern_w,r'\\1\\2\\3b\\5',text)\n",
        "        #turns word initial 'u̯' to 'v'\n",
        "        text = re.sub(r'(ˈ)u̯',r'\\1v',text)\n",
        "        text = re.sub(r'^u̯',r'v',text)\n",
        "        #deletes 'u' in hiatus when followed by 'u' or 'o'\n",
        "        text = re.sub(hiatus_w,r'\\1\\2\\4',text)\n",
        "        #reduces 'uo' to 'o:'\n",
        "        text = re.sub(hiatus_w_2, r'\\1\\2ː', text)\n",
        "        #changes 'i̯' to 'j'\n",
        "        text = re.sub(r'i̯',r'j',text)\n",
        "        #changes 'i', 'e' in hiatus to 'j'\n",
        "        text = re.sub(hiatus_j,r'\\1\\2j\\4\\5',text)\n",
        "        text = re.sub(hiatus_j_2, r'\\1j\\3\\4', text)\n",
        "        #changes stressed 'Ci' in hiatus to 'Cj'\n",
        "        text = re.sub(r'(b|p|t|d|ɡ|g|k|c|s|r|l|n|m|ʷ)(\\ˈ)(i|i̯|e)(a|e|i|o|u)',r'\\1\\2j\\4',text)\n",
        "        #reduces 'je' to 'e:'\n",
        "        text = re.sub(r'j(\\.*)e',r'\\1eː',text)\n",
        "        #deletes 'w' after geminate consonants\n",
        "        text = re.sub(gem_w,r'\\1\\2\\3',text)\n",
        "        #reduces word-initial /dj/ to 'z'\n",
        "        if text.startswith('di') or text.startswith('dj'):\n",
        "            text = ('z'+text[2:])\n",
        "        #reduces /dj/ to 'z' or 'j'\n",
        "        text = re.sub(r'(r|n)(\\.*)d[ii̯j](\\.*)([aeiouîûyj])',r'\\1\\2z\\3\\4',text)\n",
        "        text = re.sub(r'(\\ˈ\\w+)(\\.*)d[ii̯j](\\.*)([aeiouîûyj])',r'\\1\\2j\\3\\4',text)\n",
        "        text = re.sub(r'd(\\ˈ|\\.)([ii̯j])([aeiouîûyj])',r'\\1j\\3',text)\n",
        "        #reduces /gj/ to /j/\n",
        "        text = re.sub(r'ɡj',r'j',text)\n",
        "        #raises /eː/ and /oː/ before /stʲ/ to /iː/ and /uː/\n",
        "        text = re.sub(r'eː(s\\.*)(tj)',r'iː\\1\\2',text)\n",
        "        text = re.sub(r'oː(s\\.*)(tj)',r'uː\\1\\2',text)\n",
        "        #reduces 'ex', 'x' to 's'\n",
        "        text = re.sub(r'(\\ˈ*)ek(\\.*|\\ˈ*)(s)',r'\\1\\2\\3',text)\n",
        "        text = re.sub(r'k(\\.*s)(\\w+)',r's\\1\\2',text)\n",
        "        text = re.sub(r'k(\\.*s)$',r'\\1',text)\n",
        "        #palatalizes /gj/ to 'j'\n",
        "        text = re.sub(r'([aeiouîûy]\\ː+\\ˈ+)ɡ([eiîyj])',r'\\1j\\2',text)\n",
        "\n",
        "        ### added for scraping: wiktionary contains certain pronunciations and diacritics that need to be removed\n",
        "\n",
        "        #replaces IPA t͡ʃ with 'c'\n",
        "        text = re.sub(r't͡ʃ','c',text)\n",
        "        #removes hyperscript 'h' from word\n",
        "        text = re.sub(r'ʰ','',text)\n",
        "\n",
        "        return text\n",
        "\n",
        "\n",
        "#Supposed to put IPA vowels through OHG vowel shift\n",
        "    def vow_shift(text):\n",
        "        pattern_i = r'(\\ˈ)(\\w+)i(\\.)'\n",
        "        pattern_long_e = r'(\\ˈ)(\\w*)eː(\\.)'\n",
        "        pattern_long_i = r'(\\ˈ)(\\w*)iː(\\.)'\n",
        "        pattern_long_o = r'(\\ˈ)(\\w*)oː(\\.)'\n",
        "        pattern_u = r'(\\ˈ)(\\w*)u(\\.)'\n",
        "        pattern_long_u = r'(\\ˈ)(\\w*)uː(\\.)'\n",
        "        pattern_au = r'au̯'\n",
        "\n",
        "        text = re.sub(pattern_i, r'\\1\\2î\\3', text)\n",
        "        text = re.sub(pattern_long_i, r'\\1\\2ei\\3' , text)\n",
        "\n",
        "        text = re.sub(pattern_long_e, r'\\1\\2î\\3', text)\n",
        "        text = re.sub(pattern_long_o, r'\\1\\2û\\3', text)\n",
        "        text = re.sub(pattern_u, r'\\1\\2û\\3',text)\n",
        "        text = re.sub(pattern_long_u, r'\\1\\2ou\\3', text)\n",
        "        #turns diphthong 'au' into long 'o';\n",
        "        text = re.sub(r'(au̯)(\\.*|\\ˈ)(r|l|t|d|s)',r'o\\2\\3',text)\n",
        "        text = re.sub(r'au̯',r'ou',text)\n",
        "\n",
        "        return text\n",
        "\n",
        "\n",
        "    def umlaut(text):\n",
        "        umlaut_a = r'a\\ː*([bptdgkcsrlnm]*)(\\.|\\ˈ)(\\w*)(j|iː)'\n",
        "        umlaut_o = r'o\\ː*([bptdgkcsrlnm]*)(\\.|\\ˈ)(\\w*)(j|iː)'\n",
        "        umlaut_u = r'u\\ː([bptdgkcsrlnm]*)(\\.|\\ˈ)(\\w*)(j|iː)'\n",
        "        umlaut_long_o = r'û(\\.*)(\\w*[jii̯])'\n",
        "        umlaut_long_u = r'ou(\\.*)(\\w*[jii̯])'\n",
        "\n",
        "        text = re.sub(umlaut_a,r'ai\\1\\2\\3\\4',text)\n",
        "        text = re.sub(umlaut_o, r'oi\\1\\2\\3\\4', text)\n",
        "        text = re.sub(umlaut_u, r'ui\\1\\2\\3\\4',text)\n",
        "        text = re.sub(umlaut_long_o, r'ûi\\1\\2',text)\n",
        "        text = re.sub(umlaut_long_u, r'oui\\1\\2',text)\n",
        "\n",
        "        return text\n",
        "\n",
        "#Turns single consonants between vowels to fricatives;\n",
        "    def single_con(text):\n",
        "        pattern_t= r'(a\\ː*|e\\ː*|i\\ː*|î|o\\ː*|u\\ː*|û)(\\.*t)(e|i|y)'\n",
        "        pattern_t2 = r'(a\\ː*|e\\ː*|i\\ː*|î|o\\ː*|u\\ː*|û)(\\.*t)(a|o|u)'\n",
        "        pattern_t3 = r'(r|l|n)(\\.*t)(a|o|u)'\n",
        "        pattern_t4 = r'(r|l|n)(\\.*t)(i|e|j)'\n",
        "        pattern_t_end = r'[aeiou]t$'\n",
        "\n",
        "        pattern_p = r'(a\\ː*|e\\ː*|i\\ː*|î|o\\ː*|u\\ː*|û)(\\.*p)(a|e|i|o|u)'\n",
        "        pattern_p_2 = r'([mnlr])(\\.*p)(a|e|i|o|u)'\n",
        "        pattern_p_end = r'p$'\n",
        "\n",
        "        pattern_k = r'(a\\ː*|e\\ː*|i\\ː*|î|o\\ː*|u\\ː*|û|r)(ː*)(\\.*c|\\.*k)(a|o|u)'\n",
        "        pattern_k_end = r'c$|k$'\n",
        "        text = re.sub(pattern_t, r'\\1sc\\3', text)\n",
        "        text = re.sub(pattern_t2, r'\\1sç\\3', text)\n",
        "        text = re.sub(pattern_t3, r'\\1ç\\3',text)\n",
        "        text = re.sub(pattern_t4, r'\\1c\\3',text)\n",
        "        #turns /tj/ to 'sç' before a, o, or u\n",
        "        text = re.sub(r'(tj)(\\.*)(a|o|u|û)',r'sç\\2\\3',text)\n",
        "\n",
        "        text = re.sub(pattern_t_end, r'ş', text)\n",
        "\n",
        "        text = re.sub(pattern_p, r'\\1ff\\3', text)\n",
        "        text = re.sub(pattern_p_2, r'\\1ph\\3',text)\n",
        "        text = re.sub(pattern_p_end, r'f', text)\n",
        "        text = re.sub(pattern_k, r'\\1\\2ch\\4', text)\n",
        "        text = re.sub(pattern_k_end, r'h', text)\n",
        "\n",
        "        return text\n",
        "\n",
        "#Turns geminates to affricates;\n",
        "    def gem_con(text):\n",
        "        pattern_t_start1 = r'^(\\ˈ*)t(a|o|u|û)'\n",
        "        pattern_t_start2 = r'^(\\ˈ*)t(e|i|y)'\n",
        "        pattern_p_start = r'^(\\ˈ*)p(\\w+)'\n",
        "        pattern_k_start = r'^(\\ˈ*)k(\\w+)'\n",
        "        pattern_tt = r'(a|e|i|o|u|û)(t\\.*t)(\\.*e|\\.*i|\\.*y)'\n",
        "        pattern_tt2 = r'(a|e|i|o|u|û)(t\\.*t)(\\.*a|\\.*o|\\.*u)'\n",
        "        pattern_pp = r'(a|e|i|o|u|y|û)(p\\.*p)(a|e|i|o|u|y|û)'\n",
        "        pattern_kk = r'(a|e|i|o|u|û)(k\\ˈ*k|k\\.*k)(a|o|u|û)'\n",
        "        text = re.sub(pattern_p_start, r'\\1ph\\2', text)\n",
        "        text = re.sub(pattern_t_start1, r'\\1ç\\2', text)\n",
        "        text = re.sub(pattern_t_start2, r'\\1c\\2', text)\n",
        "        text = re.sub(pattern_k_start, r'\\1ch\\2',text)\n",
        "        #shifts /t/ in word if stressed\n",
        "        text = re.sub(r'(\\ˈ)t(a|o|u|û)',r'\\1ç\\2',text)\n",
        "        text = re.sub(r'(\\ˈ)t(e|i|y)',r'\\1c\\2',text)\n",
        "        #shifts /p/ in word if stressed\n",
        "        text = re.sub(r'(a\\ː*|e\\ː*|i\\ː*|î|o\\ː*|u\\ː*|û)(\\ˈ)p(a|e|i|o|u|û|î|j)',r'\\1\\2ph\\3',text)\n",
        "        #shifts /k/ in word if stressed\n",
        "        text = re.sub(r'(a\\ː*|e\\ː*|i\\ː*|î|o\\ː*|u\\ː*|û)(\\ˈ)k(a|o|u|û)',r'\\1\\2ch\\3',text)\n",
        "\n",
        "        text = re.sub(pattern_tt, r'\\1c\\3', text)\n",
        "        text = re.sub(pattern_tt2, r'\\1ç\\3', text)\n",
        "        text = re.sub(pattern_pp, r'\\1ph\\3', text)\n",
        "        text = re.sub(pattern_kk, r'\\1ch\\3', text)\n",
        "\n",
        "        return text\n",
        "\n",
        "#devoices intervocalic voiced geminate consonants\n",
        "    def voiced_gem(text):\n",
        "        pattern_bb = r'(a|e|i|o|u|y|û)(b\\ˈ*b|b\\.*b)(a|e|i|j|o|u|y|û)'\n",
        "        text = re.sub(pattern_bb, r'\\1pp\\3', text)\n",
        "        pattern_gg = r'(a|e|i|o|u|û)(g\\ˈ*g|g\\.*g)(a|o|u|û)'\n",
        "        text = re.sub(pattern_gg, r'\\1cc\\3', text)\n",
        "\n",
        "        return(text)\n",
        "\n",
        "#devoices initial voiced consonants\n",
        "    def devoice(text):\n",
        "        pattern_d = r'^(\\ˈ*)d(\\w+)'\n",
        "        text = re.sub(pattern_d, r'\\1t\\2', text)\n",
        "        pattern_g = r'^(\\ˈ*)ɡ(a|o|u|r|l)'\n",
        "        text = re.sub(pattern_g, r'\\1c\\2', text)\n",
        "        pattern_b = r'^(\\ˈ*)b(a|o|u|i|e|r|l)'\n",
        "        text = re.sub(pattern_b, r'\\1p\\2', text)\n",
        "\n",
        "        return(text)\n",
        "\n",
        "    def ipa_clean(text):\n",
        "        #removes syllable boundaries, stress markers, and length symbol\n",
        "        text = re.sub(r'[/\\ˈ\\.\\ː]',r'',text)\n",
        "        #shifts 'cj' to 'ç'\n",
        "        text = re.sub(r'kj',r'ç',text)\n",
        "        #replaces 'k' with 'c'\n",
        "        text = re.sub(r'k',r'c',text)\n",
        "\n",
        "        return(text)\n",
        "\n",
        "#Clips endings off words & replaces 'ç' w/'z' word finally\n",
        "    def clipper(text):\n",
        "        if text.endswith('o') or text.endswith('u'):\n",
        "            text = text[:-1]\n",
        "            if text.endswith('ç'):\n",
        "                text = (text[:-1]+'z')\n",
        "        elif text.endswith('us') or text.endswith('os'):\n",
        "            text=text[:-2]\n",
        "            if text.endswith('ç'):\n",
        "                text = (text[:-1]+'z')\n",
        "            elif text.endswith('hh'):\n",
        "                text = (text[:-2]+'ch')\n",
        "        elif text.endswith('um') or text.endswith('om'):\n",
        "            text = text[:-2]\n",
        "            if text.endswith('ç'):\n",
        "                text = (text[:-1]+'z')\n",
        "            elif text.endswith('ci'):\n",
        "                text = (text[:-2]+'z')\n",
        "            elif text.endswith('hh'):\n",
        "                text = (text[:-1])\n",
        "        elif text.endswith('is') or text.endswith('es'):      #have to put 's' removal rule before the IPA stripper: words ending in long vowel+'s' keep the 's'\n",
        "            text = text[:-2]\n",
        "            if text.endswith('c'):\n",
        "                text = (text[:-1]+'z')\n",
        "        elif text.endswith('em'):\n",
        "            text = text[:-2]\n",
        "            if text.endswith('sc'):\n",
        "                text = (text[:-1]+'z')\n",
        "            elif text.endswith('c'):\n",
        "                text = (text[:-1]+'z')\n",
        "        elif text.endswith('e') and len(text)>2:\n",
        "            text = text[:-1]\n",
        "            if text.endswith('c'):\n",
        "                text = (text[:-1]+'z')\n",
        "        elif text.endswith('a'):\n",
        "            text = text[:-1]\n",
        "            if text.endswith('c'):\n",
        "                text = (text[:-1]+'qu')\n",
        "            elif text.endswith('g'):\n",
        "              text = (text[:-1]+'gu')    #not sure why this isn't working\n",
        "            elif text.endswith('ç'):\n",
        "                text = (text[:-1]+'c')\n",
        "            text = (text+'e')\n",
        "        if text.endswith('nj') or text.endswith('lj'):\n",
        "            text = text\n",
        "        elif text.endswith('j'):\n",
        "            text = text[:-1]\n",
        "\n",
        "        return(text)\n",
        "\n",
        "\n",
        "\n",
        "    basodino_word = vulg_lat(word)\n",
        "    basodino_word = vow_shift(basodino_word)\n",
        "    basodino_word = umlaut(basodino_word)\n",
        "    basodino_word = single_con(basodino_word)\n",
        "    basodino_word = gem_con(basodino_word)\n",
        "    basodino_word = voiced_gem(basodino_word)\n",
        "    basodino_word = devoice(basodino_word)\n",
        "    basodino_word = ipa_clean(basodino_word)\n",
        "    basodino_word = clipper(basodino_word)\n",
        "\n",
        "\n",
        "    return(basodino_word)\n",
        "\n",
        "\n",
        "\n",
        "#result = basodino(word)\n",
        "\n",
        "#for loop to iterate over each item in list that is returned by previous block, transform it into Basodino, and then output a list of transformed terms\n",
        "\n",
        "def transform(basodino_word):\n",
        "  results = []\n",
        "  for item in word:\n",
        "    result = basodino(item)\n",
        "    results.append(result)\n",
        "  return(results)\n",
        "\n",
        "result = transform(word)\n",
        "\n",
        "print(result)\n",
        "\n",
        "\n",
        "#N.B.: the first function to run in the line below is 'vulg_lat' - NOT 'clipper'\n",
        "#basodino_word = (clipper(ipa_clean((devoice(gem_con(single_con(umlaut(vow_shift(vulg_lat(word))))))))))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgA148KqRYgR",
        "outputId": "8b75239f-5cea-4a4b-a023-7b983b287ba3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "              Latin  Basodino\n",
            "0         /ˈa.bae̯/        ab\n",
            "1       /ˈa.ba.leː/      abal\n",
            "2     /aˈbal.la.ba/  aballabe\n",
            "3    /aˈbal.la.u̯a/  aballabe\n",
            "4      /aˈba.mi.ta/    abamte\n",
            "..              ...       ...\n",
            "191   /aˈɡa.si.aːs/  aɡaisjas\n",
            "192    /aˈɡas.sae̯/     aɡass\n",
            "193     /ˈa.ɡa.tʰa/    aɡasce\n",
            "194  /a.ɡaˈtʰyr.na/  aɡacyrne\n",
            "195       /aˈɡeː.a/      aɡîe\n",
            "\n",
            "[196 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "latinIPA = pd.Series(clean2)\n",
        "bas_vocab = pd.Series(result)\n",
        "\n",
        "dict = {\n",
        "    'Latin': latinIPA,\n",
        "    'Basodino': bas_vocab\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(dict)\n",
        "\n",
        "df.to_excel('/content/drive/My Drive/Documents/Conlangs/bas_ouput.xlsx')\n",
        "\n",
        "#files.download('bas_output.xlsx')\n",
        "\n",
        "print(df)\n",
        "\n",
        "### fix log: include /s/ after long vowels at end of words; change 'sz' to 'ş'\n",
        "   # (cont.) list item #14: \"abdue\": the 'u' should have the accent mark, check the open vowel function; loss of the nasal before fricative did lengthen the vowel, cf. 'absconsa'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJfkj6YJovId"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
